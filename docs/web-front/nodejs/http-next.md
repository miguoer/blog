# HTTP 各版本分析

## HTTP/1.0

HTTP/1.0 版的主要缺点是，每个 TCP 连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。

## HTTP/1.1

HTTP/1.1 版的最大变化，就是引入了持久连接（persistent connection），即 TCP 连接默认不关闭，可以被多个请求复用，不用声明 Connection: keep-alive。

客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。不过，规范的做法是，客户端在最后一个请求时，发送 Connection: close，明确要求服务器关闭 TCP 连接。

目前，对于同一个域名，大多数浏览器允许同时建立 6 个持久连接。

1.1 版还引入了管道机制（pipelining），即在同一个 TCP 连接里面，客户端可以同时发送多个请求。这样就进一步改进了 HTTP 协议的效率。

虽然 1.1 版允许复用 TCP 连接，但是同一个 TCP 连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为"队头堵塞"（Head-of-line blocking）。

为了避免这个问题，只有两种方法：一是减少请求数，二是同时多开持久连接。这导致了很多的网页优化技巧，比如合并脚本和样式表、将图片嵌入 CSS 代码、域名分片（domain sharding）等等。如果 HTTP 协议设计得更好一些，这些额外的工作是可以避免的。

## SPDY 协议

2009 年，谷歌公开了自行研发的 SPDY 协议，主要解决 HTTP/1.1 效率不高的问题。

这个协议在 Chrome 浏览器上证明可行以后，就被当作 HTTP/2 的基础，主要特性都在 HTTP/2 之中得到继承。

## HTTP/2

2015 年，HTTP/2 发布。它不叫 HTTP/2.0，是因为标准委员会不打算再发布子版本了，下一个新版本将是 HTTP/3。HTTP/2 修改了数据格式（分帧）以及在客户端与服务器之间的传输方式，通过新的分帧层向应用隐藏了所有复杂性。

### 1.二进制分帧层

HTTP/1.1 版的头信息肯定是文本（ASCII 编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"（frame）：头信息帧和数据帧。

二进制协议的一个好处是，可以定义额外的帧。HTTP/2 定义了近十种帧，为将来的高级应用打好了基础。如果使用文本实现这种功能，解析数据将会变得非常麻烦，二进制解析则方便得多。

### 2.多路复用

在 HTTP/1.x 中，如果客户端要想发起多个并行请求以提升性能，则必须使
用多个 TCP 连接。这种模型也会导致队首阻塞，从而造成底层 TCP 连接的
效率低下。

HTTP/2 复用 TCP 连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了"队头堵塞"。

举例来说，在一个 TCP 连接里面，服务器同时收到了 A 请求和 B 请求，于是先回应 A 请求，结果发现处理过程非常耗时，于是就发送 A 请求已经处理好的部分， 接着回应 B 请求，完成后，再发送 A 请求剩下的部分。

这样双向的、实时的通信，就叫做多工（Multiplexing）。

### 3.数据流

因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

HTTP/2 将每个请求或回应的所有数据包，称为一个数据流（stream）。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流 ID，用来区分它属于哪个数据流。另外还规定，客户端发出的数据流，ID 一律为奇数，服务器发出的，ID 为偶数。

数据流发送到一半的时候，客户端和服务器都可以发送信号（RST_STREAM 帧），取消这个数据流。1.1 版取消数据流的唯一方法，就是关闭 TCP 连接。这就是说，HTTP/2 可以取消某一次请求，同时保证 TCP 连接还打开着，可以被其他请求使用。

客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应。

### 4.头信息压缩

HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，比如 Cookie 和 User Agent，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。

HTTP/2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息使用 gzip 或 compress 压缩后再发送；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

### 5.服务器推送

HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。

常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析 HTML 源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。

## HTTP/3

关于 HTTP/3 需要了解的：

- 运行在 QUIC 之上的 HTTP 协议被称为 HTTP/3(HTTP over QUIC)
- QUIC 协议（Quick UDP Internet Connection）基于 UDP，正是看中了
  UDP 的速度与效率。同时 QUIC 也整合了 TCP、TLS 和 HTTP/2 的优
  点，并加以优化。
- HTTP 3 与 HTTP 1.1 和 HTTP 2 没有直接的关系，也不是 http2 的扩展
- 减少了握手的延迟（1-RTT 或 0-RTT）
- 多路复用，并且没有 TCP 的阻塞问题
- 连接迁移，（主要是在客户端）当由 Wifi 转移到 4G 时，连接不
  会被断开。

### 队首阻塞问题

HTTP/1.1 的队头阻塞。一个 TCP 连接同时传输 10 个请求，其中第
1、2、3 个请求已被客户端接收，但第 4 个请求丢失，那么后面第 5~10 个请求都被阻塞，需要等第 4 个请求处理完毕才能被处理，这样
就浪费了带宽资源。

HTTP/2 的多路复用虽然可以解决“请求”这个粒度的阻塞，但 HTTP/2
的基础 TCP 协议本身却也存在着队头阻塞的问题。

由于 HTTP/2 必须使用 HTTPS，而 HTTPS 使用的 TLS 协议也存在队
头阻塞问题。队头阻塞会导致 HTTP/2 在更容易丢包的弱网络环境下比 HTTP/1.1
更慢

那 QUIC 解决队头阻塞问题的的方法：

- QUIC 的传输单元是 Packet，加密单元也是 Packet，整个加密、
  传输、解密都基于 Packet，这样就能避免 TLS 的队头阻塞问题；
- QUIC 基于 UDP，UDP 的数据包在接收端没有处理顺序，即使中间
  丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理。
